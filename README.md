# å­¦ä¹ ç¬”è®°
ğŸ“ ä»£ç ç»ƒä¹ 
ğŸ“Œ æç¤ºä¿¡æ¯
- [CUDA](./cuda)
    - [ã€ŠCUDA Cç¼–ç¨‹æƒå¨æŒ‡å—ã€‹](./cuda/professional_cuda_c_programming)
- [æ·±åº¦å­¦ä¹ ](./deeplearning)
    - [å´æ©è¾¾ä¸“é¡¹è¯¾ç¨‹-åºåˆ—æ¨¡å‹](./deeplearning/deep_learning_specializations/sequence_models)
- [å¤§æ¨¡å‹](./llm)
    - [æ·±å…¥æŒ–æ˜llama3çš„ä»é›¶å®ç°](./llm/deepdive_llama3_from_scratch)
    - [Coding a Transformer from scratch on PyTorch, with full explanation, training and inference.](./llm/coding_a_transformer_from_scratch_on_pytorch)
    - [Attention is all you need (Transformer) - Model explanation (including math), Inference and Training](./llm/attention_is_all_you_need_model_explanation)